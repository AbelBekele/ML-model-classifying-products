{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'description' is a text attribute and 'category' is a categorical attribute\n",
    "text_attribute = 'about_product'\n",
    "categorical_attribute = 'category'\n",
    "\n",
    "# # Load data\n",
    "data = pd.read_csv('content/amazon.csv')\n",
    "\n",
    "# data.head()\n",
    "\n",
    "# Select specific columns\n",
    "selected_data = data[['product_name', 'about_product', 'actual_price', 'category']]\n",
    "\n",
    "\n",
    "\n",
    "# Tokenization and encoding\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(selected_data[text_attribute])\n",
    "sequences = tokenizer.texts_to_sequences(selected_data[text_attribute])\n",
    "padded_sequences = pad_sequences(sequences, padding='post')\n",
    "labels = selected_data[categorical_attribute]\n",
    "\n",
    "# Encoding categorical labels\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0097s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0097s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 - 4s - loss: 5.3251 - accuracy: 0.0461 - val_loss: 5.2767 - val_accuracy: 0.0478 - 4s/epoch - 116ms/step\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abel\\Documents\\Projects\\Payever\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 - 1s - loss: 5.0648 - accuracy: 0.1297 - val_loss: 4.7413 - val_accuracy: 0.1604 - 650ms/epoch - 18ms/step\n",
      "Epoch 3/20\n",
      "37/37 - 1s - loss: 4.3922 - accuracy: 0.1587 - val_loss: 4.5001 - val_accuracy: 0.1604 - 514ms/epoch - 14ms/step\n",
      "Epoch 4/20\n",
      "37/37 - 1s - loss: 4.2634 - accuracy: 0.1587 - val_loss: 4.4816 - val_accuracy: 0.1604 - 523ms/epoch - 14ms/step\n",
      "Epoch 5/20\n",
      "37/37 - 1s - loss: 4.2470 - accuracy: 0.1587 - val_loss: 4.4835 - val_accuracy: 0.1604 - 513ms/epoch - 14ms/step\n",
      "Epoch 6/20\n",
      "37/37 - 0s - loss: 4.2142 - accuracy: 0.1587 - val_loss: 4.4722 - val_accuracy: 0.1604 - 419ms/epoch - 11ms/step\n",
      "Epoch 7/20\n",
      "37/37 - 0s - loss: 4.1980 - accuracy: 0.1587 - val_loss: 4.4584 - val_accuracy: 0.1604 - 425ms/epoch - 11ms/step\n",
      "Epoch 8/20\n",
      "37/37 - 0s - loss: 4.1506 - accuracy: 0.1587 - val_loss: 4.4225 - val_accuracy: 0.1604 - 416ms/epoch - 11ms/step\n",
      "Epoch 9/20\n",
      "37/37 - 0s - loss: 4.1064 - accuracy: 0.1587 - val_loss: 4.3858 - val_accuracy: 0.1604 - 433ms/epoch - 12ms/step\n",
      "Epoch 10/20\n",
      "37/37 - 1s - loss: 4.0582 - accuracy: 0.1587 - val_loss: 4.3532 - val_accuracy: 0.1604 - 537ms/epoch - 15ms/step\n",
      "Epoch 11/20\n",
      "37/37 - 1s - loss: 3.9968 - accuracy: 0.1587 - val_loss: 4.3191 - val_accuracy: 0.1604 - 632ms/epoch - 17ms/step\n",
      "Epoch 12/20\n",
      "37/37 - 0s - loss: 3.9530 - accuracy: 0.1587 - val_loss: 4.2862 - val_accuracy: 0.1604 - 443ms/epoch - 12ms/step\n",
      "Epoch 13/20\n",
      "37/37 - 1s - loss: 3.9055 - accuracy: 0.1587 - val_loss: 4.2502 - val_accuracy: 0.1604 - 508ms/epoch - 14ms/step\n",
      "Epoch 14/20\n",
      "37/37 - 1s - loss: 3.8540 - accuracy: 0.1587 - val_loss: 4.2342 - val_accuracy: 0.1604 - 521ms/epoch - 14ms/step\n",
      "Epoch 15/20\n",
      "37/37 - 0s - loss: 3.8139 - accuracy: 0.1587 - val_loss: 4.2269 - val_accuracy: 0.1604 - 482ms/epoch - 13ms/step\n",
      "Epoch 16/20\n",
      "37/37 - 1s - loss: 3.7757 - accuracy: 0.1587 - val_loss: 4.2052 - val_accuracy: 0.1604 - 615ms/epoch - 17ms/step\n",
      "Epoch 17/20\n",
      "37/37 - 1s - loss: 3.7496 - accuracy: 0.1587 - val_loss: 4.1647 - val_accuracy: 0.1604 - 529ms/epoch - 14ms/step\n",
      "Epoch 18/20\n",
      "37/37 - 0s - loss: 3.7072 - accuracy: 0.1587 - val_loss: 4.2090 - val_accuracy: 0.1604 - 355ms/epoch - 10ms/step\n",
      "Epoch 19/20\n",
      "37/37 - 0s - loss: 3.6788 - accuracy: 0.1587 - val_loss: 4.1572 - val_accuracy: 0.1604 - 458ms/epoch - 12ms/step\n",
      "Epoch 20/20\n",
      "37/37 - 0s - loss: 3.6478 - accuracy: 0.1604 - val_loss: 4.1733 - val_accuracy: 0.1604 - 358ms/epoch - 10ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\tmpgn2mdoyc\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\tmpgn2mdoyc\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 4.1733 - accuracy: 0.1604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/20 01:56:32 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.173336505889893\n",
      "Accuracy: 0.16040955483913422\n",
      "INFO:tensorflow:Assets written to: c:\\Users\\Abel\\Documents\\Projects\\Payever\\notebooks\\model_1713567392\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\Abel\\Documents\\Projects\\Payever\\notebooks\\model_1713567392\\data\\model\\assets\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import time\n",
    "\n",
    "# Enable auto logging\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "# Start a new run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(10000, 16, input_length=padded_sequences.shape[1]),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(len(set(labels)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'Loss: {loss}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"loss\", loss)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Save the model to the MLflow Model format\n",
    "    timestamp = int(time.time())\n",
    "    mlflow.tensorflow.save_model(model, f\"model_{timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import time\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Enable auto logging\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "# Start a new run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Sequential([\n",
    "        Embedding(10000, 32, input_length=padded_sequences.shape[1]),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(len(set(labels)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), verbose=2, callbacks=[early_stopping, lr_reduction])\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'Loss: {loss}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"loss\", loss)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Save the model to the MLflow Model format\n",
    "    timestamp = int(time.time())\n",
    "    mlflow.tensorflow.save_model(model, f\"model_{timestamp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
